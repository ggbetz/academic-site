---
widget: pages
widget_id: highlights
headless: true
weight: 45
title: AI Highlights 
subtitle: ""
content:
  page_type: project
  filter_default: 0
  filter_button:
    - name: All
      tag: "*"
    - name: Deep Learning
      tag: Deep Learning
    - name: Other
      tag: Demo
design:
  columns: "2"
  view: 2
  flip_alt_rows: false
---

Pioneering work on **Chain of Thought**
— previously termed "Thinking Aloud" — that was later
picked up by [Wei et al.](https://arxiv.org/abs/2201.11903), who demonstrated its effectiveness
with GPT-3.
[↪︎](https://arxiv.org/abs/2103.13033)

**Critical Thinking for Large Language Models**: Some of the first systematic studies
of LLM's argumentation
skills, demonstrating that LLMs can learn and extrapolate inference schemes, and that they
can be turned into multi-step **meta-reasoners** that logically analyse argumentation. 
[↪︎](https://arxiv.org/abs/2009.07185) 
[↪︎](https://arxiv.org/abs/2110.01509) 

**LLM-based multi-agent simulations** — the first of its kind according to
[this](https://github.com/Paitesanshi/LLM-Agent-Survey?tab=readme-ov-file#-more-comprehensive-summarization)
review — showing that LLM-based agents can be placed in conversational settings to study models
of multi-agent debate and natural language opinion dynamics.
[↪︎](https://www.jasss.org/25/1/2.html)

Design of a fallacy detection task that has been accepted as part of the
**Big-Bench hard [(BBH)](https://arxiv.org/abs/2210.09261)**
evaluation suite and remains difficult to solve for SOTA LLMs.

Bridging the gap between **AI and formal epistemology** 
by showing that continous reflective equilibration
allows LLMs to become epistemic agents that hold logically & probabilistically coherent beliefs and can
consistently learn from novel evidence.
[↪︎](https://doi.org/10.3389/frai.2022.900943) 
[↪︎](https://doi.org/10.1371/journal.pone.0281372)

